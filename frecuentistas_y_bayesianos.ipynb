{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3BdyHo3Fh361sk/PLkYTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3791f0affd34d9eb268b58ced6e8c1c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fc64461610234fb780bfd8048ad93bc8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Sampling chain 0, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:04\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling chain 0, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:04</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "fc64461610234fb780bfd8048ad93bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c20ec8c26b04fefaba3a3aa77dc865d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9ddd3f27e7a24a99ab4b15289b86dc71",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Sampling chain 1, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:03\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling chain 1, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:03</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "9ddd3f27e7a24a99ab4b15289b86dc71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Areliortiz/SIMULACION2/blob/main/frecuentistas_y_bayesianos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FRECUENTISTAS Y BAYESIANOS"
      ],
      "metadata": {
        "id": "FbcZE5QP-6oH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frecuentistas: Creen que la probabilidad solo tiene sentido en experimentos\n",
        "repetidos y que mide la frecuencia con la que un evento ocurre.\n",
        "\n",
        "Bayesianos: Creen que la probabilidad refleja nuestro grado de conocimiento o certeza sobre un evento, y se puede aplicar tanto a eventos repetidos como a situaciones únicas."
      ],
      "metadata": {
        "id": "lju8ge-i_Jwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5L4nSDe-2yR"
      },
      "outputs": [],
      "source": [
        "#iportar librerias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo: Mediciones de flujo de fotones.\n",
        "Apuntamos un telescopio al cielo y observamos la luz que provienede una sola estrella, tenemos los siguientes datos:\n",
        "\n",
        "$F$: flujo real de fotones de la estrella\n",
        "\n",
        "$N$: numero de mediones\n",
        "\n",
        "$F_i$: flujo observado\n",
        "\n",
        "$e_i$: error de medición"
      ],
      "metadata": {
        "id": "XxdfF6Bm_nUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2)  # para reproducibilidad\n",
        "e = np.random.normal(30, 3, 50)\n",
        "F = np.random.normal(1000, e)\n"
      ],
      "metadata": {
        "id": "LuJcUO1-_ao5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfoque frecuentista.\n",
        "\n",
        "Utiliza máxima verosimilitud para estimar parametros. En este caso, la probabilidad condicional de una medición $D_i$ dado un flujo verdadero $F$ se modela como una distribución normal:\n",
        "$P(D_i|F) = \\frac{1}{\\sqrt{2\\pi e_i^2}} \\exp\\left(-\\frac{(F_i - F)^2}{2e_i^2}\\right)$\n",
        "\n",
        "El log-verosimilitud para un conjunto de mediciones $D$ es:\n",
        "\n",
        "$\\log L(D|F) = -\\frac{1}{2} \\sum_{i=1}^N \\left[ \\log(2\\pi e_i^2) + \\frac{(F_i - F)^2}{e_i^2} \\right]$\n",
        "\n",
        "El valor que maximiza la verisimiltud es:\n",
        "\n",
        "$\\hat{F} = \\frac{\\sum w_i F_i}{\\sum w_i}, \\quad w_i = \\frac{1}{e_i^2}$\n",
        "\n",
        "La incertidumbre en $\\hat{F}$ se calcula como:\n",
        "\n",
        "$\\sigma_{\\hat{F}} = \\left(\\sum w_i\\right)^{-1/2}$"
      ],
      "metadata": {
        "id": "t7ScZBzfHCIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lo evaluamos de la sig. manera\n",
        "w = 1. / e ** 2\n",
        "F_hat = np.sum(w * F) / np.sum(w)\n",
        "sigma_F = np.sqrt(1. / np.sum(w))\n",
        "\n",
        "print(f\"Frequentista: F̂ = {F_hat:.2f} ± {sigma_F:.2f}\")\n"
      ],
      "metadata": {
        "id": "TpSZMwNGHBtL",
        "outputId": "e42db3b7-69ac-46a3-a939-1e151791df2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequentista: F̂ = 998.65 ± 4.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesianismo: Uso de probabilidades.\n",
        "\n",
        "El enfoque bayesiano calcula la distribución posterior de $F$ utilizando el teorema de Bayes:\n",
        "\n",
        "$P(F|D) = \\frac{P(D|F)P(F)}{P(D)}$\n",
        "\n",
        "Donde:\n",
        "\n",
        "$P(F|D)$: Probabilidad posterior(la meta del análisis)\n",
        "\n",
        "$P(D|F)$: Verosimilidad\n",
        "\n",
        "$P(F|D)$: Prior, que en este caso asume el plano ($P$($F$) α 1).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2w3TFYNxOm1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "si fijamos lo anterior P(F) ∝ 1 (a flat prior), tenemos.\n",
        "\n",
        "P(F|D) ∝ L (D|F). El resultado es equivalente al frecuentista en este caso.\n",
        "\n",
        "Divergencia en los resultados\n",
        "Aunque frecuentismo y bayesianismo suelen coincidir en problemas simples, en casos más complejos pueden diferir notablemente, especialmente en:\n",
        "\n",
        "Manejo de parámetros de molestia.\n",
        "Diferencias entre intervalos de confianza (frecuentistas) y regiones creíbles (bayesianas)."
      ],
      "metadata": {
        "id": "kKC3XYUqCySt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ejemplo: Juego de billar de Bayes\n",
        "- **Contexto**: Alice y Bob compiten para alcanzar seis puntos. Los puntos dependen de un marcador cuya posición, desconocida para ambos, determina el lado ganador. Alice tiene cinco puntos y Bob tres después de ocho lanzamientos. La probabilidad de ganar de Bob depende de este parámetro de molestia.\n",
        "\n",
        "Datos:\n",
        "\n",
        "B = Bob gana\n",
        "\n",
        "D = datos observados, es decir, D = (nA,nB) = (5,3)\n",
        "\n",
        "p = probabilidad desconocida de que una pelota caiga en el lado de Alice\n",
        "\n",
        "\n",
        "- **Frecuentismo**:\n",
        "   - Estima $p$, la probabilidad de que una bola favorezca a Alice, como $( \\hat{p} = \\frac{5}{8}).$\n",
        "   - Calcula la probabilidad de que Bob gane los siguientes tres puntos consecutivos:\n",
        "   $   P(B) = (1 - \\hat{p})^3 = 0.053 \\quad$ (esto es, 18 a 1 en contra de Bob).\n",
        "\n",
        "- **Bayesianismo**:\n",
        "\n",
        "   -Comenzamos aplicando la definición de probabilidad condicional\n",
        "para expandir el término $P(B, p|D):$\n",
        "\n",
        "  $P(B|D) = \\int P(B|p,D) \\cdot P(p|D) \\, dp$\n",
        "\n",
        "Ahora la probabilidad deseada se expresa en términos\n",
        "utilizando la regla de Bayes, la identidad de probabilidad obtendremos lo siguiente.\n",
        "La probabilidad deseada está expresada en términos de tres cantidades que podemos calcular:\n",
        "\n",
        "$P(B|D) = \\frac{\\int P(B|p, D) P(D|p) P(p) \\, dp}{\\int P(D|p) P(p) \\, dp}$\n",
        "\n",
        "Donde:\n",
        "\n",
        "1. $ P(B|p, D)  = (1 - p)^3 $ Probabilidad de que Bob gane los tres lanzamientos restantes.\n",
        "\n",
        "2. $   P(D|p) \\propto p^5 (1 - p)^3$): probabilidad de observar 5 éxitos para Alice y 3 para Bob\n",
        "\n",
        "3. $P(p) \\propto 1$Prior uniforme sobre $p$\n",
        "\n",
        "Juntando todo y simplificando, obtenemos:\n",
        "$P(B|D) = \\frac{\\int_0^1 (1 - p)^3 p^5 \\, dp}{\\int_0^1 (1 - p)^3 p^3 \\, dp}$\n",
        "\n",
        "Usando la libreria spacy:\n",
        "\n",
        "El bayesianismo proporciona una mejor forma de manejar parámetros de molestia mediante la marginalización.\n",
        "\n"
      ],
      "metadata": {
        "id": "_hJit-b_GmD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import beta\n",
        "P_B_D = beta(7, 6) / beta(4, 6)  # Resultado: 0.091 (odds 10 a 1 contra Bob)\n",
        "P_B_D\n"
      ],
      "metadata": {
        "id": "Bb2aQdSsB8yV",
        "outputId": "87d5a393-4b72-4372-99d9-ed6ae7eaed81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09090909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El enfoque bayesiano produce una probabilidad más precisa al considerar la incertidumbre en $p$. El frecuentismo subestima esta variabilidad.\n"
      ],
      "metadata": {
        "id": "q0Rbe2sDTl2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Intervalos de confianza vs. regiones creíbles\n",
        "- **Definiciones:**\n",
        "   - **Frecuentista:** La probabilidad se refiere a la proporción de intervalos generados que contienen el valor verdadero en experimentos repetidos.\n",
        "   - **Bayesiano:** La probabilidad se refiere a la certeza de que el parámetro desconocido está dentro de un intervalo dado los datos observados.\n",
        "\n",
        "   Esencialmente, tenemos datos \\( D \\) provenientes del modelo:\n",
        "\n",
        "$\n",
        "P(x|θ) =\n",
        "\\begin{cases}\n",
        "\\exp(θ - x), & x > θ \\\\\n",
        "0, & x < θ\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "\n",
        "- **Problema del modelo truncado exponencial:**\n",
        "   - Se estima θ , el tiempo antes de que ocurra un fallo, a partir de datos de fallos observados \\( D = \\{10, 12, 15\\} \\).\n",
        "   - **Frecuentismo:** Calcula un intervalo de confianza $CI$ usando la media muestral y su desviación estándar.\n",
        "   \n",
        "   Ejemplo:\n",
        "\n",
        "     $ CI(\\theta) = (10.2, 12.5)$\n",
        "    \n",
        "     Sin embargo, este intervalo contradice el límite $θ \\leq \\min(D) = 10.$\n",
        "   - **Bayesianismo:** Utiliza una prior plana y encuentra la región creíble (CR):\n",
        "\n",
        "     $     CR(\\theta) = (9.0, 10.0)$\n",
        "     Este intervalo respeta el límite lógico basado en los datos.\n",
        "\n",
        "Conclusión.\n",
        "El IC y el CR, represntan diferentes valores.\n",
        "Usando simulaciones de Monte Carlo, es posible confirmar que ambos resultados anteriores responden correctamente.\n",
        "\n",
        "El CR bayesiano muestra el valor de θ en sí (la probabilidad de que el parámetro esté en el CRfijo).\n",
        "\n",
        "El IC frecuentista muestra el procedimiento utilizado para construir el IC (la probabilidad de que cualquier IC potencial contenga el parámetro fijo).\n",
        "\n",
        "\n",
        "El enfoque bayesiano es más intuitivo y consistente en problemas donde los datos están restringidos o hay parámetros desconocidos. Sin embargo, ambos enfoques tienen sus aplicaciones según el problema."
      ],
      "metadata": {
        "id": "TZ1hTsTBT-ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicación: Un modelo lineal simple\n",
        "\n",
        "Se utiliza un modelo lineal con tres parámetros: intersección, pendiente y dispersión.\n",
        "Los datos se generan aleatoriamente para ajustar el modelo utilizando tanto enfoques frecuentistas como bayesianos.\n",
        "\n",
        "Para los datos $ D = \\{x_i, y_i\\} $, el modelo es:\n",
        "\n",
        "$\\hat{y}(x_i|\\alpha, \\beta) = \\alpha + \\beta x_i,$\n",
        "\n",
        "y la verosimilitud es el producto de la distribución Gaussiana para cada punto:\n",
        "\n",
        "$\n",
        "\\mathcal{L}(D|\\alpha, \\beta, \\sigma) = (2\\pi\\sigma^2)^{-N/2} \\prod_{i=1}^N \\exp\\left[-\\frac{[y_i - \\hat{y}(x_i|\\alpha, \\beta)]^2}{2\\sigma^2}\\right].$"
      ],
      "metadata": {
        "id": "Me0UvcOHcnTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluamos los punto siguientes\n",
        "import numpy as np\n",
        "np.random.seed(42)  # Repetibilidad\n",
        "theta_true = (25, 0.5)\n",
        "xdata = 100 * np.random.random(20)\n",
        "ydata = theta_true[0] + theta_true[1] * xdata\n",
        "ydata = np.random.normal(ydata, 10)  # Añadir error\n"
      ],
      "metadata": {
        "id": "GmV2CQuscm-3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frecuentista:\n",
        "El intervalo de confianza alrededor de este valor es una elipse en el espacio de parámetros definida por la siguiente matriz:\n",
        "\n",
        "$\n",
        "\\Sigma_{\\hat{\\theta}} \\equiv\n",
        "\\begin{bmatrix}\n",
        "\\sigma_\\alpha^2 & \\sigma_{\\alpha\\beta} \\\\\n",
        "\\sigma_{\\alpha\\beta} & \\sigma_\\beta^2\n",
        "\\end{bmatrix}\n",
        "= \\sigma^2 (M^T M)^{-1}.\n",
        "$\n",
        "\n",
        "Aquí, σ es nuestro término de error desconocido\n",
        "$Σ _{\\hat{\\theta}} $ representan la incertidumbre correlacionada entre las estimaciones."
      ],
      "metadata": {
        "id": "Bk21K4odhoI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#frecuentista\n",
        "X = np.vstack([np.ones_like(xdata), xdata]).T\n",
        "theta_hat = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, ydata))\n",
        "y_hat = np.dot(X, theta_hat)\n",
        "sigma_hat = np.std(ydata - y_hat)\n",
        "Sigma = sigma_hat**2 * np.linalg.inv(np.dot(X.T, X))\n"
      ],
      "metadata": {
        "id": "0PmTeH9rhERD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "X = sm.add_constant(xdata)\n",
        "result = sm.OLS(ydata, X).fit()\n",
        "print(result.summary2())\n"
      ],
      "metadata": {
        "id": "x4xGXaoIhnl5",
        "outputId": "20207369-2456-45d1-b3b2-31bb9af868f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Results: Ordinary least squares\n",
            "=================================================================\n",
            "Model:              OLS              Adj. R-squared:     0.683   \n",
            "Dependent Variable: y                AIC:                147.7737\n",
            "Date:               2024-12-09 03:48 BIC:                149.7651\n",
            "No. Observations:   20               Log-Likelihood:     -71.887 \n",
            "Df Model:           1                F-statistic:        41.97   \n",
            "Df Residuals:       18               Prob (F-statistic): 4.30e-06\n",
            "R-squared:          0.700            Scale:              86.157  \n",
            "-------------------------------------------------------------------\n",
            "            Coef.    Std.Err.     t      P>|t|     [0.025    0.975]\n",
            "-------------------------------------------------------------------\n",
            "const      24.6361     3.7871   6.5053   0.0000   16.6797   32.5924\n",
            "x1          0.4483     0.0692   6.4782   0.0000    0.3029    0.5937\n",
            "-----------------------------------------------------------------\n",
            "Omnibus:              1.996        Durbin-Watson:           2.758\n",
            "Prob(Omnibus):        0.369        Jarque-Bera (JB):        1.634\n",
            "Skew:                 0.651        Prob(JB):                0.442\n",
            "Kurtosis:             2.486        Condition No.:           100  \n",
            "=================================================================\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the\n",
            "errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos demostrar que:\n",
        "$\n",
        "P(\\sigma) \\propto \\frac{1}{\\sigma},\n",
        "$\n",
        "\n",
        "lo cual es comúnmente conocido como el **Prior de Jeffreys**  y es equivalente a un prior plano en $ \\log \\sigma $. Combinando todo esto,obtenemos para nuestro problema de regresión lineal:\n",
        "\n",
        "$\n",
        "P(\\alpha, \\beta, \\sigma) \\propto \\frac{1}{\\sigma} (1 + \\beta^2)^{-3/2}.\n",
        "$\n",
        "\n",
        "Ahora se evalua numéricamente la posterior mediante MCMC.\n"
      ],
      "metadata": {
        "id": "YfQVpy91iwmC"
      }
    },
    {
      "source": [
        "!pip install emcee"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FlX8WvD9jdiH",
        "outputId": "d5927d5e-a6ec-4029-b783-ac08629f19d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emcee\n",
            "  Downloading emcee-3.1.6-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from emcee) (1.26.4)\n",
            "Downloading emcee-3.1.6-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emcee\n",
            "Successfully installed emcee-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emcee\n",
        "def log_prior(theta):\n",
        "    alpha, beta, sigma = theta\n",
        "    if sigma < 0:\n",
        "        return -np.inf  # log(0)\n",
        "    return -1.5 * np.log(1 + beta**2) - np.log(sigma)\n",
        "\n",
        "def log_like(theta, x, y):\n",
        "    alpha, beta, sigma = theta\n",
        "    y_model = alpha + beta * x\n",
        "    return -0.5 * np.sum(np.log(2 * np.pi * sigma**2) + (y - y_model)**2 / sigma**2)\n",
        "\n",
        "def log_posterior(theta, x, y):\n",
        "    return log_prior(theta) + log_like(theta, x, y)\n"
      ],
      "metadata": {
        "id": "S5TyWX0XjVNi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, configuramos el cálculo. emcee combina varios “caminantes”\n",
        "que interactúan, cada uno de los cuales genera su propia cadena\n",
        "de Markov. También especificaremos un período de rodaje para permitir que las cadenas se estabilicen antes de dibujar nuestros trazos finales:"
      ],
      "metadata": {
        "id": "IsT4DkbnjUkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndim = 3\n",
        "nwalkers = 50\n",
        "nburn = 1000\n",
        "nsteps = 2000\n",
        "starting_guesses = np.random.rand(nwalkers, ndim)\n",
        "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=[xdata, ydata])\n",
        "sampler.run_mcmc(starting_guesses, nsteps)\n",
        "trace = sampler.chain[:, nburn:, :].reshape(-1, ndim).T\n"
      ],
      "metadata": {
        "id": "OckFDqTKkFD5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora llamamos al sampler y extraemos el rastro:"
      ],
      "metadata": {
        "id": "bjAPBzm-kP08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = emcee.EnsembleSampler(nwalkers, ndim,\n",
        "log_posterior,\n",
        "args=[xdata,ydata])\n",
        "sampler.run_mcmc(starting_guesses, nsteps)\n",
        "# chain is of shape (nwalkers, nsteps, ndim):\n",
        "# discard burn-in points and reshape:\n",
        "trace = sampler.chain[:, nburn:, :]\n",
        "trace = trace.reshape(-1, ndim).T"
      ],
      "metadata": {
        "id": "MIVifqs7kQz6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con PyMC:\n",
        "\n",
        "Modelo con decoradores:"
      ],
      "metadata": {
        "id": "Qb3yRRMTkk2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "\n",
        "# Generar datos simulados\n",
        "np.random.seed(42)\n",
        "xdata = 100 * np.random.random(20)\n",
        "true_alpha, true_beta = 25, 0.5\n",
        "ydata = true_alpha + true_beta * xdata + np.random.normal(0, 10, size=len(xdata))\n",
        "\n",
        "# Construir el modelo en PyMC3\n",
        "with pm.Model() as model:\n",
        "    # Priors para los parámetros (ajustados)\n",
        "    alpha = pm.Normal(\"alpha\", mu=25, sigma=20)  # Prior centrado cerca del valor verdadero\n",
        "    beta = pm.Normal(\"beta\", mu=0.5, sigma=1)   # Prior más estrecho\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=10)    # Prior para sigma\n",
        "\n",
        "    # Modelo determinístico para y\n",
        "    y_model = alpha + beta * xdata\n",
        "\n",
        "    # Likelihood (verosimilitud) para los datos observados\n",
        "    y = pm.Normal(\"y\", mu=y_model, sigma=sigma, observed=ydata)\n",
        "\n",
        "    # Revisar los valores iniciales\n",
        "    print(\"Puntos iniciales del modelo:\", model.initial_point)\n",
        "\n",
        "    # Configuración del muestreador MCMC\n",
        "    trace = pm.sample(1000, tune=500, cores=1, return_inferencedata=True)\n",
        "\n",
        "# Resumen de los resultados\n",
        "print(pm.summary(trace))\n"
      ],
      "metadata": {
        "id": "0thKmgFwklte",
        "outputId": "c7da3c33-42f2-49e5-87c2-9d7dea4186dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "e3791f0affd34d9eb268b58ced6e8c1c",
            "fc64461610234fb780bfd8048ad93bc8",
            "0c20ec8c26b04fefaba3a3aa77dc865d",
            "9ddd3f27e7a24a99ab4b15289b86dc71"
          ]
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntos iniciales del modelo: <bound method Model.initial_point of <pymc.model.core.Model object at 0x7f2e83984820>>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3791f0affd34d9eb268b58ced6e8c1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c20ec8c26b04fefaba3a3aa77dc865d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
            "alpha  24.609  3.824  17.347   31.480      0.127    0.090     914.0    1079.0   \n",
            "beta    0.449  0.070   0.316    0.576      0.002    0.002     897.0     938.0   \n",
            "sigma   9.592  1.663   6.793   12.773      0.055    0.039     948.0     978.0   \n",
            "\n",
            "       r_hat  \n",
            "alpha    1.0  \n",
            "beta     1.0  \n",
            "sigma    1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymc3\n",
        "\n",
        "# Extraemos datos\n",
        "S = pymc.MCMC(model)\n",
        "S.sample(iter=100000, burn=50000)\n",
        "trace = [S.trace('alpha')[:], S.trace('beta')[:], S.trace('sigma')[:]]\n"
      ],
      "metadata": {
        "id": "f2ZeqKq6mpFN",
        "outputId": "7c001642-0147-40a5-c991-bd4e018cd9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymc3\n",
            "  Downloading pymc3-3.11.6-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (0.20.0)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from pymc3) (5.5.0)\n",
            "Collecting deprecat (from pymc3)\n",
            "  Downloading deprecat-2.1.3-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting dill (from pymc3)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (1.0.3)\n",
            "Collecting numpy<1.22.2,>=1.15.0 (from pymc3)\n",
            "  Downloading numpy-1.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from pymc3) (1.0.1)\n",
            "Collecting scipy<1.8.0,>=1.7.3 (from pymc3)\n",
            "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting semver>=2.13.0 (from pymc3)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting theano-pymc==1.1.2 (from pymc3)\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pymc3) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from theano-pymc==1.1.2->pymc3) (3.16.1)\n",
            "Requirement already satisfied: setuptools>=60.0.0 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (75.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (3.8.0)\n",
            "INFO: pip is looking at multiple versions of arviz to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting arviz>=0.11.0 (from pymc3)\n",
            "  Downloading arviz-0.19.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "  Downloading arviz-0.18.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading arviz-0.17.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading arviz-0.17.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading arviz-0.16.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading arviz-0.16.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading arviz-0.15.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "INFO: pip is still looking at multiple versions of arviz to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading arviz-0.15.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading arviz-0.14.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading arviz-0.13.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading arviz-0.12.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (24.2)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (2024.10.0)\n",
            "Collecting netcdf4 (from arviz>=0.11.0->pymc3)\n",
            "  Downloading netCDF4-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (0.8.0)\n",
            "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pandas>=0.24.0 (from pymc3)\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "INFO: pip is still looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pandas-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->pymc3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->pymc3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->pymc3) (2024.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecat->pymc3) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->pymc3) (1.16.0)\n",
            "INFO: pip is looking at multiple versions of xarray to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xarray>=0.16.1 (from arviz>=0.11.0->pymc3)\n",
            "  Downloading xarray-2024.11.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "INFO: pip is still looking at multiple versions of xarray to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading xarray-2024.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2024.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading xarray-2023.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "INFO: pip is looking at multiple versions of xarray-einstats to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xarray-einstats>=0.2 (from arviz>=0.11.0->pymc3)\n",
            "  Downloading xarray_einstats-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading xarray_einstats-0.6.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting cftime (from netcdf4->arviz>=0.11.0->pymc3)\n",
            "  Downloading cftime-1.6.4.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netcdf4->arviz>=0.11.0->pymc3) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.5->arviz>=0.11.0->pymc3)\n",
            "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Downloading pymc3-3.11.6-py3-none-any.whl (872 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.6/872.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arviz-0.12.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading deprecat-2.1.3-py2.py3-none-any.whl (10 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xarray-2023.12.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xarray_einstats-0.6.0-py3-none-any.whl (31 kB)\n",
            "Downloading netCDF4-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: theano-pymc\n",
            "  Building wheel for theano-pymc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano-pymc: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529959 sha256=35abed39af7b91c48eaf060d14922ce676a5b1a24911c823ad743cb266154c39\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/da/87/4e3e2d14772741721d4ebe739c16bcf10ca3c6348f740aa852\n",
            "Successfully built theano-pymc\n",
            "Installing collected packages: semver, numpy, dill, deprecat, scipy, pandas, contourpy, cftime, xarray, theano-pymc, netcdf4, xarray-einstats, arviz, pymc3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2024.10.0\n",
            "    Uninstalling xarray-2024.10.0:\n",
            "      Successfully uninstalled xarray-2024.10.0\n",
            "  Attempting uninstall: xarray-einstats\n",
            "    Found existing installation: xarray-einstats 0.8.0\n",
            "    Uninstalling xarray-einstats-0.8.0:\n",
            "      Successfully uninstalled xarray-einstats-0.8.0\n",
            "  Attempting uninstall: arviz\n",
            "    Found existing installation: arviz 0.20.0\n",
            "    Uninstalling arviz-0.20.0:\n",
            "      Successfully uninstalled arviz-0.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.1 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.1 which is incompatible.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.1 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.1 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.1 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.1 which is incompatible.\n",
            "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.1 which is incompatible.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "langchain 0.3.9 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 1.22.1 which is incompatible.\n",
            "librosa 0.10.2.post1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.1 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.1 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "mizani 0.13.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.22.1 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.1 which is incompatible.\n",
            "plotnine 0.14.3 requires numpy>=1.23.5, but you have numpy 1.22.1 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.3 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "pymc 5.18.2 requires arviz>=0.13.0, but you have arviz 0.12.1 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.22.1 which is incompatible.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arviz-0.12.1 cftime-1.6.4.post1 contourpy-1.2.1 deprecat-2.1.3 dill-0.3.9 netcdf4-1.7.2 numpy-1.22.1 pandas-2.0.3 pymc3-3.11.6 scipy-1.7.3 semver-3.0.2 theano-pymc-1.1.2 xarray-2023.12.0 xarray-einstats-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "arviz",
                  "numpy",
                  "pandas",
                  "scipy",
                  "xarray"
                ]
              },
              "id": "c82e35db642e458386e4ef015d7e910e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'pymc' has no attribute 'MCMC'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ae43777fc848>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Extraemos datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMCMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sigma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pymc' has no attribute 'MCMC'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pystan\n",
        "model_code = \"\"\"\n",
        "data {\n",
        "    int<lower=0> N;\n",
        "    real x[N];\n",
        "    real y[N];\n",
        "}\n",
        "parameters {\n",
        "    real alpha_perp;\n",
        "    real<lower=-pi()/2, upper=pi()/2> theta;\n",
        "    real log_sigma;\n",
        "}\n",
        "transformed parameters {\n",
        "    real alpha;\n",
        "    real beta;\n",
        "    real sigma;\n",
        "    real ymodel[N];\n",
        "    alpha <- alpha_perp / cos(theta);\n",
        "    beta <- sin(theta);\n",
        "    sigma <- exp(log_sigma);\n",
        "    for (j in 1:N)\n",
        "        ymodel[j] <- alpha + beta * x[j];\n",
        "}\n",
        "model {\n",
        "    y ~ normal(ymodel, sigma);\n",
        "}\n",
        "\"\"\"\n",
        "data = {'N': len(xdata), 'x': xdata, 'y': ydata}\n",
        "fit = pystan.stan(model_code=model_code, data=data, iter=25000, chains=4)\n",
        "trace = [fit.extract()['alpha'], fit.extract()['beta'], fit.extract()['sigma']]\n"
      ],
      "metadata": {
        "id": "JoXniQQsm2b4",
        "outputId": "a7d34c40-94a3-495f-ee6a-42443dc8e726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pystan'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-98a777a40e01>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpystan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model_code = \"\"\"\n\u001b[1;32m      3\u001b[0m data {\n\u001b[1;32m      4\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreal\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pystan'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BvUzJ43Tm2DW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Kqnp5VpZmoZW"
      }
    }
  ]
}